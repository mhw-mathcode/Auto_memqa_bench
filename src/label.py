import json
import time
import os
from openai import OpenAI
import random

DEFAULT_API_KEY = os.getenv("OPENAI_API_KEY", "")
DEFAULT_BASE_URL = os.getenv("OPENAI_BASE_URL", "")
DEFAULT_MODEL = os.getenv("LABEL_MODEL", "qwen3-14b")

LABELS = [
    "äº‹å®æå–ï¼ˆå•å¯¹è¯ï¼‰",
    "äº‹å®æå–ï¼ˆå¤šå¯¹è¯ï¼‰",
    "è®°å¿†æ›´æ–°ï¼ˆå¤±æ•ˆçš„è®°å¿†ï¼Œæ›´æ–°çš„è®°å¿†ï¼‰",
    "å¤šè·³",
    "å¼ƒæƒ"
]

PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä¸ªé—®é¢˜ç±»å‹æ ‡æ³¨å™¨ï¼Œä¸éœ€è¦å›ç­”é—®é¢˜å†…å®¹ã€‚

ç»™å®šï¼š
1. ä¸€æ®µå¯¹è¯ï¼ˆconversationï¼‰
2. ä¸€ä¸ªé—®é¢˜ï¼ˆquestionï¼‰

è¯·åˆ¤æ–­ï¼šå›ç­”è¿™ä¸ªé—®é¢˜éœ€è¦å“ªä¸€ç§è®¤çŸ¥ç±»å‹ã€‚

ã€å¯é€‰æ ‡ç­¾ï¼ˆåªèƒ½é€‰ä¸€ä¸ªï¼ŒåŸæ ·è¾“å‡ºï¼Œä¸è¦è§£é‡Šï¼‰ã€‘
- äº‹å®æå–ï¼ˆå•å¯¹è¯ï¼‰
- äº‹å®æå–ï¼ˆå¤šå¯¹è¯ï¼‰
- è®°å¿†æ›´æ–°ï¼ˆå¤±æ•ˆçš„è®°å¿†ï¼Œæ›´æ–°çš„è®°å¿†ï¼‰
- å¤šè·³

ã€åˆ¤å®šæ ‡å‡†ã€‘
- å•ä¸€åœºæ™¯ã€å•ä¸€å¯¹è¯å³å¯å›ç­” â†’ äº‹å®æå–ï¼ˆå•å¯¹è¯ï¼‰
- éœ€è¦æ•´åˆå¤šæ®µå¯¹è¯ä¸­çš„äº‹å® â†’ äº‹å®æå–ï¼ˆå¤šå¯¹è¯ï¼‰
- æ¶‰åŠé”™è¯¯è®°å¿†è¢«çº æ­£ã€åæ¥æ‰å‘ç°çœŸç›¸ â†’ è®°å¿†æ›´æ–°ï¼ˆå¤±æ•ˆçš„è®°å¿†ï¼Œæ›´æ–°çš„è®°å¿†ï¼‰
- éœ€è¦æ€»ç»“äººç‰©æ€§æ ¼ã€åŠ¨æœºã€ä»·å€¼è§‚ã€é•¿æœŸä¸€è‡´æ€§ â†’ å¤šè·³

ã€å¯¹è¯ã€‘
{conversation}

ã€é—®é¢˜ã€‘
{question}

è¯·ç›´æ¥è¾“å‡ºæ ‡ç­¾ï¼š
"""

def classify_question(conversation, question, client, model):
    prompt = PROMPT_TEMPLATE.format(
        conversation=conversation,
        question=question
    )

    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„åˆ†ç±»å™¨ã€‚"},
        {"role": "user", "content": prompt}
    ]

    for attempt in range(10):
        try:
            resp = client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=0.0,
                extra_body={"enable_thinking": False},
            )

            # åŸºæœ¬åˆæ³•æ€§æ£€æŸ¥
            if (
                resp
                and resp.choices
                and resp.choices[0].message
                and resp.choices[0].message.content
            ):
                label = resp.choices[0].message.content.strip()
                return label

            raise ValueError("Empty response")

        except Exception as e:
            sleep_time = 60 + random.uniform(0, 10)
            print(f"[Retry {attempt+1}/{10}] API failed: {e}")
            time.sleep(sleep_time)

    return "null"


def label_main(input_file_path: str, output_file_path: str,
               api_key: str = DEFAULT_API_KEY, base_url: str = DEFAULT_BASE_URL,
               model_name: str = DEFAULT_MODEL) -> str:
    """
    é—®é¢˜åˆ†ç±»æ ‡æ³¨ä¸»å‡½æ•°
    
    Args:
        input_file_path: è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆv2ç‰ˆæœ¬ï¼‰
        output_file_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆv3ç‰ˆæœ¬ï¼‰
        api_key: APIå¯†é’¥
        base_url: APIåŸºç¡€URL
        model_name: æ¨¡å‹åç§°
    
    Returns:
        å¤„ç†åçš„æ–‡ä»¶è·¯å¾„
    """
    print("\n" + "="*60)
    print("ğŸ”„ æ­¥éª¤ 3: é—®é¢˜åˆ†ç±»æ ‡æ³¨")
    print("="*60)
    print(f"ğŸ“¥ è¾“å…¥æ–‡ä»¶: {input_file_path}")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(output_file_path), exist_ok=True)
    
    client = OpenAI(api_key=api_key, base_url=base_url)
    
    # è¯»å–è¾“å…¥æ–‡ä»¶
    with open(input_file_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    # å¦‚æœæ˜¯å•ä¸ªå¯¹è±¡ï¼Œåˆ™è½¬æ¢ä¸ºåˆ—è¡¨
    if isinstance(data, dict):
        data = [data]
    
    # è®¡ç®—å¾…å¤„ç†é—®é¢˜æ•°
    total_questions = sum(len(item.get("qa", [])) for item in data)
    print(f"--- æ­¥éª¤ 3 å¼€å§‹å¤„ç†ï¼šå…± {total_questions} ä¸ªé—®é¢˜ ---")
    
    # å¤„ç†æ•°æ® - ä¿æŒåŸå§‹çš„åˆ—è¡¨ç»“æ„
    final_results = []
    total_qa_count = 0
    skipped_count = 0
    
    for item in data:
        conversation = item.get("conversation", {})
        questions = item.get("qa", [])
        
        # ä¸ºæ¯ä¸ªé—®é¢˜æ·»åŠ æ ‡ç­¾
        labeled_questions = []
        for q in questions:
            # ç­›é€‰é€»è¾‘ï¼šæ£€æŸ¥ iterative_evidence_ablation ä¸­æ˜¯å¦æœ‰ round=1 ä¸” result="wrong"
            should_skip = False
            iterative_ablation = q.get("iterative_evidence_ablation", [])
            if iterative_ablation:
                for record in iterative_ablation:
                    if record.get("round") == 1 and record.get("result") == "wrong":
                        should_skip = True
                        break
            
            if should_skip:
                # æœªé€šè¿‡é¢˜ç›®åˆç†æ€§éªŒè¯ï¼šä»åç»­æµç¨‹ä¸­ç§»é™¤
                skipped_count += 1
                print(f"è·³è¿‡æ ‡æ³¨ï¼ˆæœªé€šè¿‡é¢˜ç›®åˆç†æ€§éªŒè¯ï¼‰: {q.get('question', '')[:50]}...")
            else:
                # æ­£å¸¸æ ‡æ³¨
                question_text = q.get("question", "")
                print(f"æ­£åœ¨æ ‡æ³¨: {question_text[:50]}...")
                
                label = classify_question(conversation, question_text, client, model_name)
                q["label"] = label
                labeled_questions.append(q)
                
                time.sleep(0.5)  # é˜²æ­¢é™é€Ÿ
        
        # æ·±æ‹·è´åŸå§‹itemä»¥ä¿ç•™æ‰€æœ‰å­—æ®µ
        import copy
        result_item = copy.deepcopy(item)
        # åªæ›´æ–° qa å­—æ®µ
        result_item["qa"] = labeled_questions
        final_results.append(result_item)
        total_qa_count += len(labeled_questions)
    
    # ä¿å­˜ç»“æœ - ä¿æŒåˆ—è¡¨æ ¼å¼
    with open(output_file_path, "w", encoding="utf-8") as f:
        json.dump(final_results, f, ensure_ascii=False, indent=4)
    
    # Statistics reporting removed - only report pending questions at start
    return output_file_path


def main():
    """åŸæœ‰çš„ä¸»å‡½æ•°ï¼Œä¿ç•™ç”¨äºç‹¬ç«‹è¿è¡Œ"""
    merged_conversation = {}
    all_qa = []
    session_counter = 1  # sessionè®¡æ•°å™¨

    client = OpenAI(api_key=DEFAULT_API_KEY, base_url=DEFAULT_BASE_URL)
    for idx in range(1, 6):
        with open(f"An-Enemy-of-the-People/An-Enemy-of-the-People_{idx}.json", "r", encoding="utf-8") as f:
            data = json.load(f)

        for item in data:
            conversation = item["conversation"]
            questions = item.get("qa", [])
            
            # å°†å½“å‰conversationä¸­çš„æ‰€æœ‰sessionåˆå¹¶åˆ°merged_conversationä¸­
            for session_key, session_content in conversation.items():
                new_session_key = f"session_{session_counter}"
                merged_conversation[new_session_key] = session_content
                session_counter += 1

            for q in questions:
                print(q.get("question"))
                # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä¼ å…¥å®Œæ•´çš„conversationï¼Œè€Œä¸ä»…ä»…æ˜¯å½“å‰ç‰‡æ®µçš„å¯¹è¯
                label = classify_question(conversation, q.get("question"), client, DEFAULT_MODEL)
                q["label"] = label
                all_qa.append(q)
                time.sleep(0.5)  # é˜²æ­¢é™é€Ÿ

    # åˆ›å»ºæœ€ç»ˆåˆå¹¶ç»“æœ
    merged_result = {
        "id": "merged_version",
        "conversation": merged_conversation,
        "qa": all_qa
    }

    with open("An-Enemy-of-the-People_merged.json", "w", encoding="utf-8") as f:
        json.dump(merged_result, f, ensure_ascii=False, indent=4)

    print(f"åˆå¹¶å®Œæˆï¼æ€»å…±åˆå¹¶äº† {session_counter-1} ä¸ª sessionï¼Œ{len(all_qa)} ä¸ªé—®ç­”å¯¹ã€‚")


if __name__ == "__main__":
    main()

