import json
import re
from typing import Dict, List, Any, Tuple
import os
import time
import numpy as np
from typing import Any, Dict, List, Tuple, Optional
from openai import OpenAI
import math
from src.qa_only_response import QAOnlyRunner

# --- 1. æ‰“ä¹±é¡ºåº ---

def rename_and_shuffle_options(input_file_path: str, output_file_path: str) -> None:
    """
    è¯»å– JSON æ–‡ä»¶ï¼Œè¿›è¡Œäººåæ›¿æ¢ï¼Œå¹¶æ‰“ä¹±æ¯é“é¢˜ç›®çš„é€‰é¡¹é¡ºåºã€‚

    :param input_file_path: è¾“å…¥ JSON æ–‡ä»¶çš„è·¯å¾„ã€‚
    :param output_file_path: è¾“å‡º JSON æ–‡ä»¶çš„è·¯å¾„ã€‚
    """
    try:
        # 1. è¯»å–è¾“å…¥æ–‡ä»¶
        with open(input_file_path, 'r', encoding='utf-8') as f:
            data: List[Any] = json.load(f)

    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°è¾“å…¥æ–‡ä»¶ {input_file_path}")
        return
    except json.JSONDecodeError:
        print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶ {input_file_path} JSON æ ¼å¼æ— æ•ˆ")
        return
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
        return

    # 2. éå†æ•°æ®ç»“æ„è¿›è¡Œå¤„ç† (é€‰é¡¹æ‰“ä¹±)
    new_data = []
    
    # å¤–å±‚ç»“æ„é€šå¸¸æ˜¯ List[Dict[str, List[Dict]]]
    if isinstance(data, dict):
        data = [data]
    for section in data:
        if 'qa' in section and isinstance(section['qa'], list):
            new_qa_list = []

            for item in section['qa']:
                # ä½¿ç”¨æ·±æ‹·è´ä»¥ä¿ç•™æ‰€æœ‰åµŒå¥—å­—æ®µ
                import copy
                new_item = copy.deepcopy(item)

                # ===============================
                # è¯»å–åŸå§‹ option
                # ===============================
                orig_option_list = new_item.get("option", []) or []
                if not isinstance(orig_option_list, list):
                    orig_option_list = [str(orig_option_list)]

                # ===============================
                # æ‹†åˆ† Aâ€“E ä¸ F
                # ===============================
                ae_options = []
                f_option = None

                for opt in orig_option_list:
                    opt = (opt or "").strip()
                    if opt.startswith("F.") or opt.startswith("Fï¼"):
                        f_option = opt
                    else:
                        ae_options.append(opt)

                # ===============================
                # è¯»å–åŸå§‹ç­”æ¡ˆ
                # ===============================
                original_answer = (new_item.get("answer", "") or "").strip()

                # ===============================
                # æå–æ ¸å¿ƒé—®é¢˜
                # ===============================
                question = new_item.get("question", "")
                pattern = r"\n?(.*?)(?:\n\nYou need to select)"
                match = re.search(pattern, question, re.DOTALL)

                core_question = match.group(1).strip() if match else question

                # ===============================
                # å·¥å…·å‡½æ•°ï¼šå»æ‰ "A. "
                # ===============================
                def _strip_letter_prefix(s: str) -> str:
                    s = (s or "").strip()
                    parts = s.split(". ", 1)
                    return parts[1].strip() if len(parts) == 2 and len(parts[0]) == 1 else s

                # ===============================
                # è§£æåŸæ­£ç¡®ç­”æ¡ˆæ­£æ–‡
                # ===============================
                if len(original_answer) == 1 and original_answer.isalpha():
                    idx = ord(original_answer.upper()) - ord('A')
                    if 0 <= idx < len(ae_options):
                        answer_body = _strip_letter_prefix(ae_options[idx])
                    else:
                        answer_body = original_answer
                else:
                    answer_body = _strip_letter_prefix(original_answer)

                # ===============================
                # åª shuffle Aâ€“E
                # ===============================
                option_bodies = [_strip_letter_prefix(opt) for opt in ae_options]

                rng = np.random.default_rng()
                rng.shuffle(option_bodies)

                # ===============================
                # é‡æ–°ç”Ÿæˆ Aâ€“E
                # ===============================
                new_option_list = []
                new_correct_answer = ""

                option_letters = ['A', 'B', 'C', 'D', 'E'][:len(option_bodies)]

                for letter, body in zip(option_letters, option_bodies):
                    new_opt_full = f"{letter}. {body}"
                    new_option_list.append(new_opt_full)
                    if body == answer_body and not new_correct_answer:
                        new_correct_answer = new_opt_full

                # ===============================
                # F æ”¾å›æœ€åï¼ˆä¸å‚ä¸æ‰“ä¹±ï¼‰
                # ===============================
                if f_option:
                    new_option_list.append(f_option)
                    if original_answer.startswith("F"):
                        new_correct_answer = f_option
                else:
                    # å¦‚æœåŸæœ¬æ²¡æœ‰ Fï¼Œå¯é€‰æ‹©æ˜¯å¦è¡¥ä¸€ä¸ª
                    new_option_list.append(
                        "F. Cannot infer the answer based on the given information."
                    )

                # ===============================
                # å†™å›ç»“æœ
                # ===============================
                new_item["option"] = new_option_list
                new_item["answer"] = new_correct_answer or original_answer

                new_item["question"] = f"""
    {core_question}

    You need to select the correct answer from the following options:
    {new_option_list}
    """.strip()

                new_qa_list.append(new_item)

            # æ·±æ‹·è´sectionä»¥ä¿ç•™æ‰€æœ‰å­—æ®µ
            import copy
            new_section = copy.deepcopy(section)
            new_section["qa"] = new_qa_list
            new_data.append(new_section)
            
    # 3. å†™å…¥è¾“å‡ºæ–‡ä»¶
    try:
        with open(output_file_path, 'w', encoding='utf-8') as f:
            json.dump(new_data, f, indent=4, ensure_ascii=False)

        # Statistics reporting moved to start of pipeline

    except Exception as e:
        print(f"âŒ å†™å…¥è¾“å‡ºæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")

# --- 2. response + eval ---

def run_qa_only(answer_llm_config, dataset_name, max_workers, output_file):
    runner = QAOnlyRunner(
        output_file,
        answer_llm_config=answer_llm_config,
    )
    runner.process_data_file(
        f"{dataset_name}", 
        max_workers=max_workers
    )
    runner.close()

# è§„åˆ™è¯„ä¼°
def run_eval(idx, file):
    def extract_option(s):
        if not isinstance(s, str):
            return None
        m = re.match(r"\s*([A-F])", s)
        return m.group(1) if m else None

    with open(file, "r", encoding="utf-8") as f:
        data = json.load(f)

    for key, items in data.items():
        for item in items:
            ans = extract_option(item.get("answer", ""))
            resp = item.get("response_option", "")
            if ans and resp and ans == resp:
                item["score"] = 1
            else:
                item["score"] = 0

    with open(f"temp/result_{idx}.json", "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

# --- 3. ç»Ÿè®¡ç»“æœï¼Œå¤šæ¬¡å›ç­” ---
def aggregate_and_analyze_results(num_files: int, prefix: str, suffix: str, threshold: float, result_file: str, conversation_file):
    """
    èšåˆå¤šä¸ª JSON æ–‡ä»¶çš„ç»“æœï¼Œç»Ÿè®¡æ¯é¢˜çš„æ­£ç¡®æ¬¡æ•°å’Œæ­£ç¡®ç‡ï¼Œå¹¶æ ‡è®°æ±¡æŸ“ã€‚
    """
    # å­˜å‚¨æ‰€æœ‰é¢˜ç›®çš„ç»Ÿè®¡æ•°æ®:
    # Key: æå–å‡ºçš„æ ¸å¿ƒé—®é¢˜æ–‡æœ¬ (e.g., "Regarding money, who did Ariel most habitually rely on?")
    # Value: { "correct_count": int, "total_count": int, "details": original_data, "responses": [str] }

    def extract_core_question(full_question_text: str) -> str:
        """
        ä»å®Œæ•´çš„ 'question' å­—æ®µä¸­æå–é—®é¢˜çš„æ ¸å¿ƒæ–‡æœ¬ã€‚
        ä¾‹å¦‚ï¼šä» 'Please answer the question: ...\n\nYou need to select...' ä¸­æå–æ ¸å¿ƒé—®é¢˜ã€‚
        """
        # æŸ¥æ‰¾ "Please answer the question: " å’Œ "\n\nYou need to select" ä¹‹é—´çš„å†…å®¹
        match = re.search(
            r"\s*(.*?)\s*\n\s*\n\s*You need to select",
            full_question_text,
            re.DOTALL
        )
        if match:
            # æå–æ ¸å¿ƒé—®é¢˜ï¼Œå¹¶ç§»é™¤é¦–å°¾çš„ç©ºç™½å’Œæ¢è¡Œç¬¦
            core_text = match.group(1).split('\n\n')[0].strip()
            question_line = core_text.split('\n')[0].strip()
            return question_line
        
        # å¦‚æœæ­£åˆ™åŒ¹é…å¤±è´¥ï¼Œè¿”å›åŸå§‹æ–‡æœ¬çš„å‰å‡ è¡Œä½œä¸ºå›é€€
        return full_question_text.split('\n')[1].strip() if full_question_text else "UNKNOWN_QUESTION"
    
    question_stats: Dict[str, Dict[str, Any]] = {}
    
    print(f"--- å¼€å§‹èšåˆæ¥è‡ª {num_files} ä¸ªæ–‡ä»¶çš„å®éªŒç»“æœ ---")

    for i in range(1, num_files + 1):
        file_name = f"{prefix}{i}{suffix}"
        if not os.path.exists(file_name):
            print(f"âš ï¸ è­¦å‘Š: æ–‡ä»¶ {file_name} ä¸å­˜åœ¨ï¼Œè·³è¿‡ã€‚")
            continue

        try:
            with open(file_name, 'r', encoding='utf-8') as f:
                data = json.load(f)
                results_list = data.get("0", [])
        except Exception as e:
            print(f"âŒ é”™è¯¯: è¯»å–æ–‡ä»¶ {file_name} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            continue

        print(f"âœ… æˆåŠŸè¯»å–æ–‡ä»¶: {file_name}ï¼ŒåŒ…å« {len(results_list)} ä¸ªæ¡ç›®ã€‚")

        for item in results_list:
            full_question_text = item.get("question", "")
            score = item.get("score", 0.0)
            response_option_w_content = item.get("response_option_w_content", "NO_RESPONSE")
            response_time = item.get("response_time", 0.0)
            pollution_check_prompt = item.get("pollution_check_prompt", 0.0)
            
            # æå–æ ¸å¿ƒé—®é¢˜æ–‡æœ¬ä½œä¸ºå”¯ä¸€é”®
            core_question_text = extract_core_question(full_question_text)

            if not core_question_text or core_question_text == "UNKNOWN_QUESTION":
                continue

            # åˆå§‹åŒ–æˆ–æ›´æ–°ç»Ÿè®¡æ•°æ®
            if core_question_text not in question_stats:
                # ä¿ç•™åŸå§‹æ ‡æ³¨ä¿¡æ¯ä½œä¸ºè¯¦æƒ…ï¼Œä½†å»é™¤ score å’Œ response
                details = item.copy()
                details.pop("score", None)
                details.pop("response_option", None)
                details.pop("response_option_w_content", None)
                details.pop("all_responses_and_scores", None)
                details.pop("contamination_status", None)
                details.pop("adversarial_answer", None)
                details.pop("response_time", None)
                
                # æå–å¹¶ä¿å­˜æ ¸å¿ƒé—®é¢˜æ–‡æœ¬
                details["core_question"] = core_question_text
                
                question_stats[core_question_text] = {
                    "correct_count": 0,
                    "total_count": 0,
                    "details": details,
                    "responses_and_scores": [], # ç”¨äºè®°å½•æ¯æ¬¡çš„ response å’Œ score
                    "pollution_check_prompt": pollution_check_prompt
                }
            
            # ç»Ÿè®¡æ€»æ¬¡æ•°
            question_stats[core_question_text]["total_count"] += 1
            
            # ç»Ÿè®¡ç­”å¯¹æ¬¡æ•°
            if score == 1.0:
                question_stats[core_question_text]["correct_count"] += 1

            # è®°å½•æœ¬æ¬¡å®éªŒçš„ response å’Œ score
            question_stats[core_question_text]["responses_and_scores"].append({
                "response_option_w_content": response_option_w_content,
                "score": score,
                "response_time": response_time,
                "file_id": i
            })

    # ----------------------------------------------------
    # 2. è®¡ç®—æ­£ç¡®ç‡å’Œæ ‡è®°æ±¡æŸ“
    # ----------------------------------------------------
    
    final_results = []
    
    print("\n--- è®¡ç®—æ­£ç¡®ç‡å¹¶è¿›è¡Œæ±¡æŸ“æ ‡è®° ---")

    for core_question_text, stats in question_stats.items():
        correct_count = stats["correct_count"]
        total_count = stats["total_count"]
        
        # è®¡ç®—æ­£ç¡®ç‡
        accuracy = correct_count / total_count if total_count > 0 else 0.0
        
        # å¤åˆ¶åŸå§‹è¯¦æƒ…
        result_item = stats["details"].copy()
        
        # æ ‡è®°æ±¡æŸ“
        if accuracy > threshold:
            pollution_flag = f"suspected"
        else:
            pollution_flag = f"good"

        result_item["pollution_check"] = {
            "result": pollution_flag,
            "correct_count": correct_count,
            "total_count": total_count,
            "accuracy": f"{accuracy:.4f}",
            "all_responses_and_scores": stats["responses_and_scores"],
        }
            
        final_results.append(result_item)

    # ----------------------------------------------------
    # 3. è¾“å‡ºç»“æœ
    # ----------------------------------------------------
    # æŠŠ conversation é™„åŠ ä¸Š
    with open(conversation_file, "r", encoding="utf-8") as f:
        data = json.load(f)
    conversation = data[0]["conversation"]

    output_data = [{"qa": final_results, "conversation": conversation}]

    try:
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=4, ensure_ascii=False)
        # Statistics reporting removed - only report pending questions at start
    except Exception as e:
        print(f"âŒ é”™è¯¯: å†™å…¥è¾“å‡ºæ–‡ä»¶æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")

# --- 4. membership_inference ---
def run_membership_inference_loss_api(
    candidate_path: str,
    output_path: str = "membership_results_api.json",
    *,
    api_key: Optional[str] = None,
    base_url: str = "https://api.siliconflow.cn/v1",
    model_name: str = "Qwen/Qwen3-14B",
    api_sleep: float = 0.0,
    top_print: int = 5,
    verbose: bool = True,
    return_sorted: bool = True,
    k_percent: float = 0.2, # Min-K% Prob çš„æ¯”ä¾‹å‚æ•°
) -> List[Dict[str, Any]]:
    """
    æ”¹è¿›ç‰ˆ MI æ¢æµ‹ï¼šæ”¯æŒ Min-K% Loss ç®—æ³•ï¼Œå¢å¼ºå¯¹é•¿å°¾çŸ¥è¯†æ±¡æŸ“çš„è¯†åˆ«èƒ½åŠ›ã€‚
    """
    if api_key is None:
        api_key = os.getenv("OPENAI_API_KEY") or os.getenv("API_KEY") or ""
    if not api_key:
        raise ValueError("api_key ä¸ºç©ºï¼šè¯·é€šè¿‡å‚æ•° api_key ä¼ å…¥ï¼Œæˆ–è®¾ç½®ç¯å¢ƒå˜é‡")

    client = OpenAI(api_key=api_key, base_url=base_url)

    # =====================
    # 1. é²æ£’çš„æ•°æ®åŠ è½½é€»è¾‘
    # =====================
    def load_qas_from_json(path: str) -> List[Dict[str, Any]]:
        with open(path, "r", encoding="utf-8") as f:
            raw = json.load(f)
        samples = []
        # å…¼å®¹ list[dict] ç»“æ„ï¼Œä¸”å¤„ç†å†…éƒ¨æœ‰ "qa" åˆ—è¡¨çš„æƒ…å†µ
        if isinstance(raw, list):
            for idx, item in enumerate(raw):
                if "qa" in item and isinstance(item["qa"], list):
                    for j, qa in enumerate(item["qa"]):
                        samples.append({
                            "outer_id": str(item.get("id", f"idx_{idx}")),
                            "inner_id": j,
                            "question": qa["question"],
                            "answer": qa["answer"],
                            "pollution_check": qa.get("pollution_check"), # 10æ¬¡é—®ç­”æ•°æ®åœ¨æ­¤
                            "category": qa.get("category")
                        })
                elif "question" in item:
                    samples.append({
                        "outer_id": str(item.get("outer_id", "na")),
                        "inner_id": item.get("inner_id", idx),
                        "question": item["question"],
                        "answer": item["answer"],
                        "pollution_check": item.get("pollution_check")
                    })
        return samples

    # =====================
    # 2. Token-level API è°ƒç”¨
    # =====================
    def call_llm(prompt: str) -> Tuple[List[str], List[float]]:
        # ä½¿ç”¨ echo=True è·å–å…¨æ–‡æœ¬çš„ logprobs
        completion = client.completions.create(
            model=model_name,
            prompt=prompt,
            temperature=0.0,
            logprobs=1,
            echo=True,
            max_tokens=1 # ä»…åšæ¢æµ‹ï¼Œä¸ç”Ÿæˆæ–° token
        )
        choice = completion.choices[0]
        lp = choice.logprobs
        return list(lp.tokens), list(lp.token_logprobs)

    # =====================
    # 3. Min-K% Loss æ ¸å¿ƒè®¡ç®—
    # =====================
    def compute_enhanced_loss(question: str, answer: str) -> Dict[str, float]:
        tokens_q, _ = call_llm(question)
        tokens_qa, logprobs_qa = call_llm(question + answer)

        len_q = len(tokens_q)
        answer_logprobs = logprobs_qa[len_q:] # æˆªå–ç­”æ¡ˆéƒ¨åˆ†çš„ logprobs
        
        if not answer_logprobs:
            return {"avg_loss": 999.0, "mink_loss": 999.0, "answer_len": 0}

        # è®¡ç®—æ‰€æœ‰ token çš„ Negative Log-Likelihood (NLL)
        nll_list = [-lp for lp in answer_logprobs]
        
        # æŒ‡æ ‡ A: æ ‡å‡†å¹³å‡ Loss
        avg_loss = sum(nll_list) / len(nll_list)

        # æŒ‡æ ‡ B: Min-K% Loss (å­¦æœ¯ç•Œé˜²æ±¡æŸ“æ›´æ¨è)
        # é€‰å– Loss æœ€é«˜çš„ k% ä¸ª token (å³æ¨¡å‹è®¤ä¸ºæœ€éš¾ã€æ¦‚ç‡æœ€ä½çš„è¯)
        sorted_nll = sorted(nll_list, reverse=True)
        k_count = max(1, int(len(nll_list) * k_percent))
        mink_loss = sum(sorted_nll[:k_count]) / k_count

        return {
            "avg_loss": float(avg_loss),
            "mink_loss": float(mink_loss),
            "ppl": math.exp(min(avg_loss, 20)), # é˜²æ­¢æº¢å‡º
            "answer_len": len(answer_logprobs),
        }

    # =====================
    # 4. ä¸»æ‰§è¡Œæµç¨‹
    # =====================
    samples = load_qas_from_json(candidate_path)
    if verbose:
        print(f"[Info] Loaded {len(samples)} samples. Starting MI detection...")

    results = []
    for idx, sample in enumerate(samples):
        try:
            scores = compute_enhanced_loss(sample["question"], sample["answer"])
            
            record = {
                **sample, # ä¿ç•™åŸå§‹ question, answer, pollution_check
                "global_index": idx,
                "avg_loss": scores["avg_loss"],
                "mink_loss": scores["mink_loss"],
                "ppl": scores["ppl"],
                "answer_len": scores["answer_len"],
            }
            results.append(record)
            
            if verbose and (idx + 1) % 10 == 0:
                print(f"  Processed {idx+1}/{len(samples)} | Loss: {scores['avg_loss']:.4f}")
            
            if api_sleep > 0:
                time.sleep(api_sleep)
        except Exception as e:
            print(f"Error at sample {idx}: {e}")

    # æŒ‰ avg_loss å‡åºæ’åºï¼ˆLoss è¶Šä½ï¼Œæ±¡æŸ“å«Œç–‘è¶Šå¤§ï¼‰
    if return_sorted:
        results.sort(key=lambda x: x["avg_loss"])
    
    # ç»™æ¯æ¡ç»“æœå¢åŠ  rank æ ‡ç­¾
    for rank, item in enumerate(results):
        item["rank_by_loss"] = rank

    # ä¿å­˜ç»“æœ
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    return results

# --- 5. è¿è¡Œé…ç½® ---
NUM = 1
INPUT_FILE_PREFIX = "./temp/result_"
INPUT_FILE_SUFFIX = ".json"
CONTAMINATION_THRESHOLD = 0.50  # æ­£ç¡®ç‡ >= 50% æ ‡è®°ä¸ºå¯èƒ½è¢«æ±¡æŸ“

def pollution_check_main(
    args,
    input_file_path: str,
    output_file_path: str,
    enable_contamination_check: bool = False
) -> str:
    """
    æ•°æ®æ±¡æŸ“æ£€æŸ¥ä¸»å‡½æ•°
    
    Args:
        args: å‘½ä»¤è¡Œå‚æ•°
        input_file_path: è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆv0ç‰ˆæœ¬ï¼‰
        output_file_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆv1ç‰ˆæœ¬ï¼‰
    
    Returns:
        å¤„ç†åçš„æ–‡ä»¶è·¯å¾„
    """
    print("\n" + "="*60)
    print("ğŸ”„ æ­¥éª¤ 1: æ•°æ®æ±¡æŸ“æ£€æŸ¥ï¼ˆæ‰“ä¹±é€‰é¡¹ï¼‰")
    print("="*60)
    
    def build_provider_config(model_value, base_url_value, api_key_value, optional_fields=None):
        config = {}
        if model_value:
            config["model"] = model_value
        if base_url_value:
            config["base_url"] = base_url_value
        if api_key_value:
            config["api_key"] = api_key_value
        if optional_fields:
            for key, value in optional_fields.items():
                if value not in (None, ""):
                    config[key] = value
        return config

    answer_llm_model = args.answer_llm_model
    answer_llm_base_url = args.answer_llm_base_url
    answer_llm_api_key = args.answer_llm_api_key
    answer_llm_config = build_provider_config(answer_llm_model, answer_llm_base_url, answer_llm_api_key)

    max_workers = args.max_workers

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(output_file_path), exist_ok=True)
    
    # è®¡ç®—å¾…å¤„ç†é—®é¢˜æ•°
    with open(input_file_path, 'r', encoding='utf-8') as f:
        input_data = json.load(f)
    total_questions = sum(len(item.get("qa", [])) for item in input_data)
    print(f"--- æ­¥éª¤ 1 å¼€å§‹å¤„ç†ï¼šå…± {total_questions} ä¸ªé—®é¢˜ ---")
    
    # æ‰“ä¹±é€‰é¡¹é¡ºåº
    rename_and_shuffle_options(input_file_path, output_file_path)
    
    # å¯é€‰çš„æ±¡æŸ“æ£€æµ‹
    # if enable_contamination_check:
    #     temp_file = "temp/result_temp.json"
    #     for idx in range(1, NUM + 1):
    #         run_qa_only(answer_llm_config, output_file_path, max_workers, temp_file)
    #         run_eval(idx, temp_file)
    #     aggregate_and_analyze_results(
    #         NUM,
    #         INPUT_FILE_PREFIX,
    #         INPUT_FILE_SUFFIX,
    #         CONTAMINATION_THRESHOLD,
    #         output_file_path,
    #         conversation_file=output_file_path
    #     )

    return output_file_path

